# ü§ñ AI Chatbot using Streamlit, LangChain & Google Gemini

Welcome to the **AI Chatbot Project**, a fully interactive conversational assistant built using **Streamlit**, **LangChain**, and **Google Gemini Generative AI**.  
This project demonstrates how modern LLMs can be integrated with user-friendly interfaces to create a real-time chatbot capable of understanding queries, generating meaningful responses, and maintaining conversation history within a session.

The chatbot is designed to simulate a natural conversation by continuously tracking user interactions and providing context-aware replies. Through the integration of the Gemini model and LangChain‚Äôs message history system, users can enjoy a seamless and engaging AI experience similar to modern chat platforms.  
This repository serves as a great starting point for developers, researchers, and students who want to explore Generative AI, prompt engineering, and conversational UI development in Python.

---

## üìå Overview

This chatbot application allows users to communicate with an AI assistant directly from their browser.  
The interface prompts users to enter their **Google API key**, ensuring secure access to the Gemini model. Once authenticated, users can ask questions or request information, and the chatbot streams responses in real time.

The app leverages:
- **Streamlit** for the web interface
- **LangChain** for prompt templating and chat history management
- **Google Gemini** for AI-powered responses

This combination creates a robust conversational system with minimal setup and maximum flexibility, making it ideal for experimentation, learning, or extension into larger real-world products.

---

## üß† How It Works

1. **User Enters API Key:**  
   The application securely accepts the user‚Äôs Google API key to authenticate requests.

2. **Prompt Template Configuration:**  
   A system prompt ensures the chatbot responds as a helpful English-speaking assistant, while LangChain dynamically injects user queries and stored message history.

3. **Model Invocation:**  
   Using the `gemini-2.5-flash` model, the chatbot generates instant responses with streaming capabilities to enhance interaction.

4. **History Tracking:**  
   The conversation is preserved using `StreamlitChatMessageHistory`, allowing continuity and contextual memory during the session.

5. **Dynamic Response Display:**  
   The generated response is displayed progressively, creating the effect of real-time typing and giving users feedback as the model processes the request.

Through these steps, users experience a smooth and highly interactive chat session with meaningful and context-aware output.

---

## üìù Features

- ü§ñ **AI responses powered by Google Gemini Generative Models**
- üí¨ **Session-based message history** that keeps track of past user interactions
- ‚ö° **Real-time streaming replies** for a typing effect and instant interaction
- üåê **Web-based chat interface** built entirely with Streamlit
- üîë **Secure API key input system** (credentials never stored permanently)
- üìö **Prompt templating** using LangChain for structured conversation flow
- üß© **Easily customizable** for future enhancements like voice input or multi-language output

---

## üìÇ File Included

> The main chatbot logic is contained in the `chatbot.py` file:
>  
> üìÑ *chatbot.py* ‚Äî complete implementation of the conversational AI system  
> *(This file includes LangChain message templates, Google Gemini model configuration, streaming response logic, and Streamlit interface setup.)*

---

## üõ†Ô∏è Installation

To run the chatbot locally, follow the steps below:

### 1Ô∏è‚É£ Clone the repository
```bash
git clone https://github.com/your-username/ai-chatbot.git
cd ai-chatbot
